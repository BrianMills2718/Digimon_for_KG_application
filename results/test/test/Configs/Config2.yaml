llm:
  api_type: "openai"  # you're using OpenAI's hosted models
  base_url: "https://api.openai.com/v1"
  model: "o3-mini"
  api_key: "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"

embedding:
  api_type: "openai"
  api_key: "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"
  model: "text-embedding-3-small"
  cache_dir: ""
  dimensions: 1024
  max_token_size: 8102
  embed_batch_size: 128
  embedding_func_max_async: 16

data_root: "./Data"  # can be empty or created later

working_dir: ./results  # output directory
exp_name: test
